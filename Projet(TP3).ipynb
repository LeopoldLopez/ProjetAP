{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qjWcjWFVcs7"
   },
   "source": [
    "# Projet Apprentissage Profond :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3mdNJJXc6Wy"
   },
   "source": [
    "## Chargement des données\n",
    "La base de données est à télécharger depuis Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_OkpjrpFXXG",
    "outputId": "e2c70a9a-506f-4904-8285-fd10fc766bd0"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/LeopoldLopez/ProjetAP.git\n",
    "path = \"./ProjetAP/Données_Triee\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoSVj5OGXa-4"
   },
   "source": [
    "Chargement des données dans des tenseurs $x$ et $y$ de dimensions respectives $(N, 64, 64, 3)$ et $(N, 1)$, où $N$ désigne le nombre d'éléments de l'ensemble considéré (apprentissage, validation, ou test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcNp4xl0QfOT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "image_size = 64\n",
    "def load_data(data_path, classes, dataset='train', image_size=64):\n",
    "    num_images = 0\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_path, dataset, class_name)\n",
    "        # Compter le nombre d'images dans le répertoire de chaque classe\n",
    "        num_images += sum(1 for item in os.listdir(class_dir) if not item.startswith('.'))\n",
    "\n",
    "    x = np.zeros((num_images, image_size, image_size, 3))\n",
    "    y = np.zeros((num_images, 1))\n",
    "    current_index = 0\n",
    "\n",
    "    # Parcourir les différents répertoires pour collecter les images\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_path, dataset, class_name)\n",
    "        for item in os.listdir(class_dir):\n",
    "            if not item.startswith('.'):\n",
    "                item_path = os.path.join(class_dir, item)\n",
    "                if os.path.isfile(item_path):\n",
    "                    # Ouvrir l'image\n",
    "                    img = Image.open(item_path)\n",
    "                    # Conversion en RGB\n",
    "                    img = img.convert('RGB')\n",
    "                    # Redimensionnement de l'image et écriture dans la variable de retour x\n",
    "                    img = img.resize((image_size, image_size))\n",
    "                    x[current_index] = np.asarray(img)\n",
    "                    # Écriture du label associé dans la variable de retour y\n",
    "                    y[current_index] = class_index\n",
    "                    current_index += 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "labels = ['Bleuets', 'Jacinthes', 'Jonquille', 'Lily_of_the_valley', 'Marguerites', 'Orchidee','Peony', 'Rose', 'Tournesol', 'Violettes']\n",
    "\n",
    "x_train, y_train = load_data(path, labels, dataset='train', image_size=64)\n",
    "x_train = x_train/255\n",
    "x_val, y_val = load_data(path, labels, dataset='validation', image_size=64)\n",
    "x_val = x_val/255\n",
    "x_test, y_test = load_data(path, labels, dataset='test', image_size=64)\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwngS1p9V1VN"
   },
   "source": [
    "### Visualisation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YXUxcuIPOS5W",
    "outputId": "ac56f270-7975-41b3-8a15-9a04b46d3fcd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "shuffle_indices = np.random.permutation(9)\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    image = x_train[shuffle_indices[i]]\n",
    "    plt.title(labels[int(y_train[shuffle_indices[i]])])\n",
    "    plt.imshow(image)\n",
    "\n",
    "print(labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV5s1T3yWJB6"
   },
   "source": [
    "## Première approche : réseau convolutif de base comme utilisé dans le TP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00T5cUGlif9z"
   },
   "source": [
    "Les images ont toutes été redimensionnées en $64 \\times 64$.\n",
    "Vous devez définir un réseau de neurones convolutif en suivant ce schéma pour la base convolutive :\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1bwXaIgO-pKJGs6fVaX0IrLbFbUAlTvNM\" style=\"width:800;height:400px;\"></center>\n",
    "<caption><center><b> Figure 2: Vue de l'architecture à implémenter </b></center></caption>\n",
    "\n",
    "Ce réseau alterne dans une première phase les couches de convolution et de Max Pooling (afin de diviser à chaque fois la dimension des tenseurs par 2).\n",
    "\n",
    "La première couche comptera 32 filtres de convolution, la seconde 64, la troisième 96 et la 4e 128. Enfin, avant la couche de sortie, vous ajouterez une couche dense comptant 512 neurones. Vous aurez donc construit un réseau à 6 couches, sorte de version simplifiée d'AlexNet.\n",
    "\n",
    "Pour construire ce réseau, vous pouvez utiliser les fonctions Conv2D, Maxpooling2D, et Flatten de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktYvE7Poiyhm"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWqVtzWZIsOY"
   },
   "source": [
    "### Entrainement\n",
    "\n",
    "Evaluation quantitative avec matrice de confusion\n",
    "Evaluation qualitative en prenant les images une par une et en regardant pk il se trompe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q9IQIETzLI-"
   },
   "source": [
    "Pour l'entraînement, vous pouvez utiliser directement les hyperparamètres suivants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjxiaPrN3Qpn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJsJ7mMIjCGm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
    "              metrics=['sparse_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNbGxTZt4cck"
   },
   "source": [
    "... puis lancer l'entraînement. **Attention : si jamais vous voulez relancer l'entraînement, il faut réinitialiser les poids du réseau. Pour cela il faut re-exécuter les cellules précédentes à partir de la définition du réseau !** Sinon vous risquez de repartir d'un entraînement précédent (qui s'est éventuellement bien, ou mal déroulé) et mal interpréter votre nouvel entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OF9mIcrJNbE"
   },
   "source": [
    "#### Sans Augmentation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjetcQRljJC8",
    "outputId": "52e20ac0-8fc3-4784-f699-97c80b254047"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=32,callbacks=[checkpoint, early_stopping])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohSfS7HHJYkY"
   },
   "source": [
    "#### Avec Augmentation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWqTRRuZJcbR",
    "outputId": "0b79bf31-99ff-4780-d8d6-fe5cf41eae65"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.ToGray(0.6),\n",
    "    A.RandomRotate90(0.3),\n",
    "    A.Flip(0.3),\n",
    "    A.Transpose(0.3),\n",
    "    A.RandomBrightnessContrast(0.5),\n",
    "    A.HueSaturationValue(0.5),\n",
    "    A.RGBShift(0.5),\n",
    "    A.RandomGamma(0.5),\n",
    "])\n",
    "#On essaie de réduire la dépendance de notre réseaux au couleur d'où les fortes probabiltés sur les augmentations colorimétriques\n",
    "\n",
    "\n",
    "def transform_images(x_train, y_train):\n",
    "    transformed_x = []\n",
    "    transformed_y = []\n",
    "    for i, x in enumerate(x_train):\n",
    "      if random.random() < 1.0:\n",
    "        transformed_x.append(x)\n",
    "        transformed_y.append(y_train[i])\n",
    "\n",
    "        transformed_image = transform(image=(x * 255).astype(np.uint8))['image']\n",
    "\n",
    "        transformed_x.append((transformed_image/255).astype(np.float64))\n",
    "        transformed_y.append(y_train[i])\n",
    "\n",
    "      else :\n",
    "        transformed_x.append(x)\n",
    "        transformed_y.append(y_train[i])\n",
    "\n",
    "    print(np.array(transformed_x).shape)\n",
    "    return np.array(transformed_x),np.array(transformed_y)\n",
    "\n",
    "transformed_images = transform_images(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iax53Tk6NMRx",
    "outputId": "2db1fcc7-b0e7-4865-d4e8-0680f656e6ef"
   },
   "outputs": [],
   "source": [
    "#ATTENTION n'oubliez pas de recompiler le model avant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(transformed_images[0], transformed_images[1], validation_data=(x_val, y_val), epochs=50, batch_size=32,callbacks=[checkpoint, early_stopping])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBPk-patWSYX"
   },
   "source": [
    "### Analyse des résultats du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "casoAuXmzWYb"
   },
   "source": [
    "Les quelques lignes suivantes permettent d'afficher l'évolution des métriques au cours de l'entraînement, sur les ensembles d'apprentissage et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fExCbSI3V6Ur"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_analysis(history):\n",
    "    acc = history.history['sparse_categorical_accuracy']\n",
    "    val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'b', linestyle=\"--\", label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', linestyle=\"--\", label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "ex3AjPOPu2UN",
    "outputId": "880836bf-4200-4d6b-d7c8-7181670b9d08"
   },
   "outputs": [],
   "source": [
    "plot_training_analysis(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gESYe5LHjyY9"
   },
   "source": [
    "###Matrice de confusion\n",
    "\n",
    "On affiche la matrice de confusion obtenue pour les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "id": "QZZNxlegjtgH",
    "outputId": "cab5587c-8086-4e06-ce94-d091cf59710b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "prediction_list = prediction.tolist()\n",
    "prediction_finale = []\n",
    "\n",
    "# On extrait la prédiction finale\n",
    "for i in range(len(prediction_list)):\n",
    "  max_local = 0\n",
    "  index = 0\n",
    "  for j in range(len(prediction_list[i])):\n",
    "    if prediction_list[i][j] > max_local:\n",
    "      max_local = prediction_list[i][j]\n",
    "      index = j\n",
    "  prediction_finale.append(index)\n",
    "\n",
    "# Création de la matrice de confusion\n",
    "cm = confusion_matrix(y_test, prediction_finale)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "cm_display.plot()\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.gca().xaxis.set_ticklabels(labels)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.gca().yaxis.set_ticklabels(labels)\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_true=y_test, y_pred=prediction_finale)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_A6fmvPW36D"
   },
   "source": [
    "##Transfer Learning\n",
    "#Tentative avec Resnet50\n",
    "Pas fructueuse, on atteint pas plus de 0.6 en sparse categorical accuracy sur les données de validation, avec une taille d'image de 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYlHI4YKLfVS",
    "outputId": "3129b500-52aa-489e-806f-e91703e0d92c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_data(data_path, classes, dataset='train', image_size=224):\n",
    "    num_images = 0\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_path, dataset, class_name)\n",
    "        num_images += sum(1 for item in os.listdir(class_dir) if not item.startswith('.'))\n",
    "\n",
    "    x = np.zeros((num_images, image_size, image_size, 3))\n",
    "    y = np.zeros((num_images, 1))\n",
    "    current_index = 0\n",
    "\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_path, dataset, class_name)\n",
    "        for item in os.listdir(class_dir):\n",
    "            if not item.startswith('.'):\n",
    "                item_path = os.path.join(class_dir, item)\n",
    "                if os.path.isfile(item_path):\n",
    "                    img = Image.open(item_path)\n",
    "                    img = img.convert('RGB')\n",
    "                    img = img.resize((image_size, image_size))\n",
    "                    x[current_index] = np.asarray(img)\n",
    "                    y[current_index] = class_index\n",
    "                    current_index += 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "labels = ['Bleuets', 'Jacinthes', 'Jonquille', 'Lily_of_the_valley', 'Marguerites', 'Orchidee', 'Peony', 'Rose', 'Tournesol', 'Violettes']\n",
    "\n",
    "image_size = 224\n",
    "x_train, y_train = load_data(path, labels, dataset='train', image_size=image_size)\n",
    "x_train = x_train / 255.0\n",
    "x_val, y_val = load_data(path, labels, dataset='validation', image_size=image_size)\n",
    "x_val = x_val / 255.0\n",
    "x_test, y_test = load_data(path, labels, dataset='test', image_size=image_size)\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffaz1T68bW6w"
   },
   "source": [
    "On fait de l'augmentation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykju-jlMbOb1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Augmentation de données\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPvLzCKlbiDw",
    "outputId": "be7b5577-9e44-4403-9319-d31be274d6ca"
   },
   "outputs": [],
   "source": [
    "# On load le ResNet50 sans le layer du dessus\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# On freeze le base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# On ajoute des couches personalisées\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# On compile le model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3rGu1W-bk_X",
    "outputId": "60453fa1-d280-456d-b864-a6af309665c2"
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "# Entrainement\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# On fine-tune le model (on unfreeze quelques couches du modèle de base et on le reentraine avec un learning rate plus bas)\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-5),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history_fine = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         epochs=20,\n",
    "                         callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "\n",
    "model.load_weights('best_model.h5')\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amhTv0cgcRVo"
   },
   "source": [
    "#MobileNetV2 :\n",
    "\n",
    "\n",
    "\n",
    "Nous avons choisi MobileNetV2 pour son efficacité avec des images 128x128. Les données ont été chargées, redimensionnées et normalisées (valeurs entre 0 et 1). Nous avons utilisé l'augmentation de données avec rotations (20°), décalages (20%), zoom (20%), et flips horizontaux pour améliorer la généralisation.\n",
    "\n",
    "Nous avons utilisé MobileNetV2 sans les couches supérieures et ajouté des couches personnalisées : GlobalAveragePooling2D pour réduire la dimensionnalité, BatchNormalization pour stabiliser l'entraînement, une couche Dense de 512 unités avec activation ReLU, une couche Dropout de 50% pour prévenir le surapprentissage, et une couche Dense finale avec 10 unités pour les classes de fleurs avec activation softmax.\n",
    "\n",
    "L'entraînement initial a gelé les couches de MobileNetV2 pour entraîner uniquement les nouvelles couches avec un taux d'apprentissage de 1e-3. Ensuite, nous avons dégelé les 30 dernières couches de MobileNetV2 et réduit le taux d'apprentissage à 1e-4 pour un fine-tuning. Des callbacks comme ModelCheckpoint, EarlyStopping et ReduceLROnPlateau ont été utilisés pour optimiser l'entraînement. Cette approche a amélioré la performance du modèle en classification des fleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pz5Gmn6dM1De"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(data_path, classes, dataset='train', image_size=128):\n",
    "    num_images = 0\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_path, dataset, class_name)\n",
    "        num_images += sum(1 for item in os.listdir(class_dir) if not item.startswith('.'))\n",
    "\n",
    "    x = np.zeros((num_images, image_size, image_size, 3))\n",
    "    y = np.zeros((num_images, 1))\n",
    "    current_index = 0\n",
    "\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_path, dataset, class_name)\n",
    "        for item in os.listdir(class_dir):\n",
    "            if not item.startswith('.'):\n",
    "                item_path = os.path.join(class_dir, item)\n",
    "                if os.path.isfile(item_path):\n",
    "                    img = Image.open(item_path)\n",
    "                    img = img.convert('RGB')\n",
    "                    img = img.resize((image_size, image_size))\n",
    "                    x[current_index] = np.asarray(img)\n",
    "                    y[current_index] = class_index\n",
    "                    current_index += 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "labels = ['Bleuets', 'Jacinthes', 'Jonquille', 'Lily_of_the_valley', 'Marguerites', 'Orchidee', 'Peony', 'Rose', 'Tournesol', 'Violettes']\n",
    "\n",
    "image_size = 128\n",
    "x_train, y_train = load_data(path, labels, dataset='train', image_size=image_size)\n",
    "x_train = x_train / 255.0\n",
    "x_val, y_val = load_data(path, labels, dataset='validation', image_size=image_size)\n",
    "x_val = x_val / 255.0\n",
    "x_test, y_test = load_data(path, labels, dataset='test', image_size=image_size)\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAcP4wGfdjAp"
   },
   "source": [
    "On verifie la distribution des classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ne9KB4PVdgzA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_class_distribution(y, labels):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    plt.bar(labels, counts)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of images')\n",
    "    plt.title('Class distribution')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(y_train, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHNuSTkpdso1"
   },
   "source": [
    "On réalise l'augmentation de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sFsIw5FdwmK"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nVik1lud0Pa"
   },
   "outputs": [],
   "source": [
    "# On load MobileNetV2 sans le layer du dessus\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# On gèle le base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# On ajoute des couches personalisées\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-3),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Entrainement du modèle\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[checkpoint, early_stopping, reduce_lr])\n",
    "\n",
    "\n",
    "# On fine-tune le model (on unfreeze quelques couches du modèle de base et on le reentraine avec un learning rate plus bas)\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history_fine = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         epochs=20,\n",
    "                         callbacks=[checkpoint, early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluation du modèle sur le set de test\n",
    "model.load_weights('best_model.h5')\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TER1aUXMd8RR"
   },
   "source": [
    "On plot la loss et l'accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIPqng3Xd7wH"
   },
   "outputs": [],
   "source": [
    "# Plot des valeurs du training et validation accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot des valeurs du training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKsBb-EJ5BzK"
   },
   "source": [
    "###Matrice de confusion\n",
    "\n",
    "On affiche la matrice de confusion obtenue pour les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X49ATV_YkMT9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "prediction_list = prediction.tolist()\n",
    "prediction_finale = []\n",
    "\n",
    "# On extrait la prédiction finale\n",
    "for i in range(len(prediction_list)):\n",
    "  max_local = 0\n",
    "  index = 0\n",
    "  for j in range(len(prediction_list[i])):\n",
    "    if prediction_list[i][j] > max_local:\n",
    "      max_local = prediction_list[i][j]\n",
    "      index = j\n",
    "  prediction_finale.append(index)\n",
    "\n",
    "# Création de la matrice de confusion\n",
    "cm = confusion_matrix(y_test, prediction_finale)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "cm_display.plot()\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.gca().xaxis.set_ticklabels(labels)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.gca().yaxis.set_ticklabels(labels)\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_true=y_test, y_pred=prediction_finale)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
